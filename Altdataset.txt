import os.path as osp
import os
import glob
import torch
import cv2
import scipy
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import numpy as np
from pyparsing import Empty
from torch.utils.data import Dataset
from torchvision.io import read_image
from torchvision import tv_tensors
from torchvision.transforms.v2 import functional as F
from torchvision.ops import masks_to_boxes
import torchvision
from triton.language import tensor


def extract_poly(file_path):
    mat_data = scipy.io.loadmat(file_path)
    data = mat_data['polygons']
    polys = [[ml, mr, yl, yr] for ml, mr, yl, yr in
             zip(data['myleft'][0], data['myright'][0], data['yourleft'][0], data['yourright'][0])]
    polys = [np.array(polys, dtype=object)]   # Trick, um ndarray mit gemischt. Dimension zu umgehen (NumPy unterstü. keine gem. Dim. direkt!)
    # print(polys)    # representative Darstellung einer matlab-File

    return polys

def polygons_to_binary_mask(polygon, width, height):
    # blk_img = Image.new("L", (width, height), 0)
    blk_img = np.zeros((720, 1280), dtype= np.uint8) #handeln wenn mask leer ist

    # polygon_list = polygon.flatten().tolist()
    polygon_list = polygon.reshape(-1,1,2)

    if len(polygon_list) == 0:
        return blk_img
    pts = np.int32(polygon_list)
    cv2.fillPoly(blk_img, [pts], [255])
    # ImageDraw.Draw(blk_img).polygon(polygon_list, outline=1, fill=1)
    # mask = np.array(blk_img)
    # return mask
    return blk_img


def beatboxing(mask):
    x_values = []
    y_values = []
    for item in mask:
        if len(item) == 2:
            x, y = item
            x_values.append(x)
            y_values.append(y)
        else:
            x_values.append(np.array([]))
            y_values.append(np.array([]))

    if any(i > 0 for i in x_values) and any(i > 0 for i in y_values):
        min_x = min(i for i in x_values if i > 0)
        max_x = max(i for i in x_values if i > 0)
        min_y = min(i for i in y_values if i > 0)
        max_y = max(i for i in y_values if i > 0)

        tupel1 = (min_x, min_y)
        tupel2 = (max_x, max_y)
        bbmatrix = np.array([tupel1, tupel2])
    # print("das ist bbmatrix:", bbmatrix)
        bbmatrix = bbmatrix.flatten()
        return bbmatrix
    else: return []

def mktensorboxes(bbmatrixmyleft, bbmatrixmyright, bbmatrixyourleft, bbmatrixyourright):    #Etwas lang geworden
    empty_tensor = torch.tensor([])  # Tensor shape (4,) und mit 0 gefüllt
    if len(bbmatrixmyleft) != 0:
        tensor_boxesml = tv_tensors.BoundingBoxes(bbmatrixmyleft, format="XYXY", canvas_size=[720, 1280])
    else:
        tensor_boxesml = empty_tensor
    if len(bbmatrixmyright) != 0:
        tensor_boxesmr = tv_tensors.BoundingBoxes(bbmatrixmyright, format="XYXY", canvas_size=[720, 1280])
    else:
        tensor_boxesmr = empty_tensor
    if len(bbmatrixyourleft) != 0:
        tensor_boxesyl = tv_tensors.BoundingBoxes(bbmatrixyourleft, format="XYXY", canvas_size=[720, 1280])
    else:
        tensor_boxesyl = empty_tensor
    if len(bbmatrixyourright) != 0:
        tensor_boxesyr = tv_tensors.BoundingBoxes(bbmatrixyourright, format="XYXY", canvas_size=[720, 1280])
    else:
        tensor_boxesyr = empty_tensor

    valid_tensors = []  # Gebe nur die mit Werten befüllten\gültigen B-Boxes. Bsp: Es gibt 3 BB, gebe 3 BB aus, anstatt 4 und einer ist kaputt.
    for tensor in [tensor_boxesml, tensor_boxesmr, tensor_boxesyl,tensor_boxesyr]:  # Überprüfung Nicht-Leerheit jedes Tensors
        if tensor.size(0) != 0:  # Wenn die erste Dimension nicht Länge 0 hat
            valid_tensors.append(tensor.squeeze(0))
    if valid_tensors:
        tensor_boxes = torch.stack(valid_tensors)
        return tensor_boxes
    else:
        print("Keine gültigen Tensoren; BoundaryBoxes in mktensorboxes zum Stacken.")

# def get_box(masks):
#     for m in masks:
#     # for i in range(num_objs):
#     #     pos = np.nonzero(masks[i])
#         ''' Get the bounding box of a given mask '''
#         pos = np.where(m)   # find out the position where a_mask=1
#         # print("postype", type(pos)) #Tupel
#         xmin = np.min(pos[1])  # min pos will give min co-ordinate
#         xmax = np.max(pos[1])   # max-position give max co-ordinate
#         ymin = np.min(pos[0])
#         ymax = np.max(pos[0])
#         return (xmin, ymin, xmax, ymax)

# def getboxes(masks):
#     boxes_appended = []
#     # maske = torch.tensor([])
#     #Um die Boxen-Tensors zusammenzuführen, weil nur das Durchlaufen einzelner Masken (=einzelner Hände) ging. Um jeder Hand's Box in einer Variable abzuspeichern
#     for i, m in enumerate(masks):
#         boxes_appended.append(get_box(m))   #[[118, 661, 290, 716], [645, 574, 870, 719], [593, 360, 774, 498], [411, 315, 532, 411]]
#
#     return boxes_appended

class Mydataset(torch.utils.data.Dataset):

    #path = osp.normpath(osp.join(osp.dirname(__file__), "egohands_dir"))
    # files = glob.glob(os.path.join('path', 'to', 'dir', '*.jpg'))
    #print(path)
    def __init__(self, _, transforms=None):
        self.imgs = []
        self.polys = []
        self.transforms = transforms
        self.path = osp.normpath(osp.join(osp.dirname(__file__), "data"))

        for dir in os.listdir(self.path):
            full_dir_path = os.path.join(self.path, dir)
            if os.path.isdir(full_dir_path):
                files = sorted(os.listdir(full_dir_path))
                for file in files:
                    if file.startswith('frame'):
                        img_path = os.path.join(full_dir_path, file)
                        self.imgs.append(img_path)  # Append image to the list
                    elif file.startswith('polygons'):
                        file_path = os.path.join(full_dir_path, file)
                        self.polys  = self.polys  + extract_poly(file_path)

    def __getitem__(self, idx):
        img = cv2.imread(self.imgs[idx])  # Load image
        img = tv_tensors.Image(img)
        img = img.permute(2, 0, 1)
        #ValueError: images is expected to be a list of 3d tensors of shape [C, H, W], got torch.Size([720, 1280])

        my_left, my_right, your_left, your_right = self.polys[0][idx] # yourright 1 Maske, zu dem bild(idx)

        # z.B bob2 [] idx 129
        # bob2shape (1, 0)            # K.w! es kann nichts gefunden werden daher ist BB auch [] leer!  Sollte auch hier (1,4) sein     # Eher schwierig
        # bob2shapemr (1, 0)        # Sollte (129, 1) sein
        bbmatrixmyleft = np.array(beatboxing(my_left))
        bbmatrixmyright   = np.array(beatboxing(my_right))
        bbmatrixyourleft   = np.array(beatboxing(your_left))
        bbmatrixyourright = np.array(beatboxing(your_right))
        # bbmatrixyourright = list(bbmatrixyourright)
        # boxes_tensor = torch.tensor(bbmatrixyourright)
        # Expected target boxes to be a tensor of shape [N, 4], got torch.Size([1, 1, 4]).   BOXES!!!!
        # Überprüfen ob Elemente im ndarray leer sind, falls nicht, machen:  ##Etwas lang geworden
        tensor_boxes = mktensorboxes(bbmatrixmyleft, bbmatrixmyright, bbmatrixyourleft, bbmatrixyourright)
        # tensor_boxes = (torch.stack([tensor_boxesml.squeeze(0), tensor_boxesmr.squeeze(0), tensor_boxesyl.squeeze(0), tensor_boxesyr.squeeze(0)]))
        # tensor_boxes = tensor_boxes.unsqueeze(0)
        # tensor_boxes = tensor_boxes.squeeze() # Train_from_Aladdin geht damit, aber main_from_utorial geht damit nicht also kann das weg
        ##

       # Bitweise IDs für die Masken definieren, sonst werden in der all-masks = ml + mr + yl + yr Addition alle Einsen zusammenaddiert, das führt zu 510, 765 etc
        my_left_id = 1 << 0  # 0001 = 1
        my_right_id = 1 << 1  # 0010 = 2
        your_left_id = 1 << 2  # 0100 = 4
        your_right_id = 1 << 3  # 1000 = 8

        # Masken mit IDs multiplizieren
        my_left_mask = my_left_id * torch.tensor(polygons_to_binary_mask(my_left, 1280, 720), dtype=torch.int32)
        my_right_mask = my_right_id * torch.tensor(polygons_to_binary_mask(my_right, 1280, 720), dtype=torch.int32)
        your_left_mask = your_left_id * torch.tensor(polygons_to_binary_mask(your_left, 1280, 720), dtype=torch.int32)
        your_right_mask = your_right_id * torch.tensor(polygons_to_binary_mask(your_right, 1280, 720), dtype=torch.int32)
        # Bitweises OR        print(all_masks)
        all_masks = my_left_mask | my_right_mask | your_left_mask | your_right_mask
        # Number of Bounding Boxes
        obj_ids = np.array(list(range(4)))
        obj_ids = torch.unique(all_masks)
        ## Split mask into seperate mask
        masks = (all_masks == obj_ids[:, None, None]).to(dtype=torch.uint8)
        # masks = torch.stack([masksml, masksmr, masksyl, masksyr])
        masks = tv_tensors.Mask(masks)
        ##

        tensor_labels = torch.ones((4,), dtype=torch.int64)
        # tensor_labels = tensor_labels.squeeze()
        ##

        image_id = idx
        ##

        # Rechnen durch alle Zeilen des Tensors durch und gibt area zeilenweise aus, als ein Tensor aus
        area = (tensor_boxes[:, 3] - tensor_boxes[:, 1]) * (tensor_boxes[:, 2] - tensor_boxes[:, 0])
        tensor_area = torch.tensor(area)
        # tensor_area = tensor_area.unsqueeze(0)
        # tensor_area = tensor_area.squeeze()
        ##

        iscrowd = torch.zeros((4,), dtype=torch.int64)
        tensor_iscrowd = iscrowd
        ##

        target =  {'boxes': tensor_boxes,  # Tensor der Form [N, 4] # Nr. 3
            'labels': tensor_labels,  # Tensor der Form [N]     #
            'masks': masks,  # Tensor der Form [N, H, W]
            'image_id': image_id,  # Tensor der Form [N]
            'area': tensor_area,  # Tensor der Form [N]
            'iscrowd': tensor_iscrowd}  # Tensor der Form [N]
        #Disable when cheking with clean_test.if _name_ = '_main_':
        if self.transforms is not None:
            img, target = self.transforms(img, target)
        # print(target)
        return img, target

    def __len__(self):
        return len(self.imgs)




